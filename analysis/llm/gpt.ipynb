{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-zk2af6da35eeba0728a4e4ded82f5a66144660282e42e179\",\n",
    "    base_url=\"https://flag.smarttrot.com/v1/\"\n",
    ")\n",
    "\n",
    "def extract_code_from_content(language, content):\n",
    "    start = content.find(\"```\")\n",
    "    if start == -1:\n",
    "        return content\n",
    "\n",
    "    end = content.find(\"```\", start + 3)\n",
    "    if end == -1:\n",
    "        return content\n",
    "\n",
    "    code_block = content[start + 3:end].strip()\n",
    "\n",
    "    first_newline = code_block.find(\"\\n\")\n",
    "    if first_newline != -1:\n",
    "        # 如果找到换行符，说明有语言标记，去掉这一行\n",
    "        code_block = code_block[first_newline:].strip()\n",
    "    if language != \"c&cpp\":\n",
    "        return code_block\n",
    "    elif language == \"c&cpp\":\n",
    "        return code_block.split(\"int main()\")[0]\n",
    "    return code_block\n",
    "def call_with_message(temperature,num_of_sequence,messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=4096,\n",
    "        n=num_of_sequence\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "LANGUAGE_LIST = [\"java\"]\n",
    "QUESTION_PATH = r\"E:\\code\\code_back\\python_project\\llm\\qa\\question\\all_question.json\"\n",
    "PASS_NUMBER = 10\n",
    "temperature = 0\n",
    "num_of_sequence = 1\n",
    "if PASS_NUMBER == 1:\n",
    "    temperature = 0\n",
    "    num_of_sequence = 1\n",
    "elif PASS_NUMBER == 10:\n",
    "    temperature = 0.8\n",
    "    num_of_sequence = 10\n",
    "MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "ANSWER_PATH = rf\"E:\\code\\code_back\\python_project\\llm\\qa\\{MODEL_NAME}_answer\"\n",
    "for language in LANGUAGE_LIST:\n",
    "    with open(QUESTION_PATH, \"r\", encoding=\"utf8\") as file:\n",
    "        question_list = json.load(file)\n",
    "        for question in tqdm(question_list):\n",
    "            all_response = []\n",
    "            try:\n",
    "                prompt = question[\"language_version_list\"][language]['prompt']\n",
    "                if prompt == \"\":\n",
    "                    continue\n",
    "                messages = [\n",
    "                    {'role': 'user',\n",
    "                     'content': prompt + \".give me all code,include import statement, no examples are required.\"}\n",
    "                ]\n",
    "                response = call_with_message(temperature, num_of_sequence, messages)\n",
    "                for idx, choice in enumerate(response.choices, 1):\n",
    "                    all_response.append({\"index\": idx, \"model_name\": MODEL_NAME,\n",
    "                                         \"response_code\": extract_code_from_content(language, choice.message.content)})\n",
    "                    print(extract_code_from_content(language, choice.message.content))\n",
    "                question[\"language_version_list\"][language][\"answer_list\"] = all_response\n",
    "                with open(f\"{ANSWER_PATH}/{language}_answer_pass{PASS_NUMBER}.jsonl\", \"a+\", encoding='utf8') as file:\n",
    "                    json_str = json.dumps(question)\n",
    "                    file.write(json_str + \"\\n\")\n",
    "                    file.flush()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            print(f\"{question['task_id']} start answer finish\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
